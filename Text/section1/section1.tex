\section*{Введение}

\section{Предварительные сведения}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Выделение сообществ в графах}

Исторически, изучение сетей происходило в рамках теории графов, которая начала своё существование с решения Леонардом Эйлером задачи о кёнигсбергских мостах. В 1920-х взял своё начало анализ социальных сетей и лишь последние двадцать лет развивается изучение \emph{сложных сетей}, то есть сетей с неправильной, сложной структурой, в некоторых случаях рассматривают динамически меняющейся во времени сложные сети. От изучения маленьких сетей внимание переходит к сетям из тысяч или миллионов узлов.

В процессе изучения сложных систем, построенных по реальным системам, оказалось, что распределение степеней $P(s)$, определённое как доля узлов со степенью $s$ среди всех узлов графа, сильно отличается от распределения Пуассона, которое ожидается для случайных графов. Также сети, построенные по реальным системам характеризуются короткими путями между любыми двумя узлами и большим количеством маленьких циклов \cite{Boccaletti&al:2006}. Это показывает, что модели, предложенные теорией графов, часто будут оказываться далеко от реальных потребностей.

Современное изучение сложных сетей привнесло значительный вклад в понимание реальных систем. Сложные сети с успехом были применены в таких разных областях, как изучение структуры и топологии интернета \cite{Faloutsos&al:1999, Broder&al:2000}, эпидемиологии \cite{Moore&Newman:2000}, биоинформатике \cite{Zhao&al:2006}, поиске преступников \cite{Hong&al:2009}, социологии \cite{Scott:2012} и многих других.

Свойством, присутствуещим почти у любой сети, является структура сообществ, разделение узлов сети на разные группы узлов так, чтобы внутри каждой группы соединений между узлами много, а соединений между узлами разных групп мало. Способность находить и анализировать подобные группы предоставляет большие возможности в изучении реальных систем, представленных с помощью сложных сетей. Плотно связанные группы узлов в социальных сетях представляют людей, принадлежащих социальным сообществам, плотно сплочённые группы узлов в интернете соответствуют страницам, посвящённым распространённым темам, а сообщества в генетических сетях связаны с функциональными модулями \cite{Boccaletti&al:2006}. Таким образом, выделение сообществ в сети является мощным инструментом для понимания функциональности сети.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Определения и обозначения}

Формально, сложная система может быть представлена с помощью графа. В этой работе будут рассматриваться только невзвешенные неориентированные графы. Неориентированный невзвешенный граф $G = (\mathscr{N}, \mathscr{L})$ состоит из двух множеств --- множества $\mathscr{N} \ne \emptyset$, элементы которого называются \emph{узлами} или \emph{вершинами} графа, и множества $\mathscr{L}$ неупорядоченных пар из множества $\mathscr{N}$, элементы которого называются \emph{рёбрами} или \emph{связями}. Мощности множеств $\mathscr{N}$ и $\mathscr{L}$ равны $N$ и $L$ соответственно.

Подграфом называется граф $G' = (\mathscr{N}', \mathscr{L}')$, где $\mathscr{N}' \subset \mathscr{N}$ и $\mathscr{L}' \subset \mathscr{L}$.

Узел обычно обозначают по его порядковому месту $i$ в множестве $\mathscr{N}$, а ребро, соединяющее пару узлов $i$ и $j$ обозначается $l_{ij}$. Узлы, между которыми есть ребро называются \emph{смежными}. Степенью узла назовём величину $s_i$, равную количеству рёбер, выходящих узла $i$.

Прогулка из узла $i$ в узел $j$ --- это последовательность узлов, начинающаяся с узла $i$ и заканчивающаяся узлом $j$. Путь --- это прогулка, в которой каждый узел встречается единожды. Геодезический путь --- это кратчайший путь, а количество узлов в нём на один больше геодезического расстояния.

До того, как мы определили понятие \emph{сообщество}, определим \emph{разбиение} на сообщества. Пусть $G = (\mathscr{N}, \mathscr{L})$ --- граф, тогда разбиением на сообщества будет называться разбиение множества его вершин $P = \{C_1, \dots, C_K\}$, то есть $\bigcup_{i = 1}^K C_i = \mathscr{N}$ и $C_i \cap C_j = \emptyset \ \forall i \neq j \in 1..K$.

Сообщество --- это такой подграф, чьи узлы плотно связаны, однако структурная сплочённость узлов можно определить по разному. Одно из определений вводит понятие \emph{клик}. Клик --- это максимальный такой подграф, состоящий из трёх и более вершин, каждая из которых связана с каждой другой вершиной из клика. $n$-клик --- это максимальный подграф, в котором самое большое геодезическое расстояние между любыми двумя вершинами не превосходит $n$. Другое определение гласит, что подграф $G'$ является сообществом, если сумма всех степеней внутри $G'$ больше суммы всех степеней, направленных в остальную часть графа \cite{Wasserman:1994}. Сообщества называются смежными, если существует ребро, направленное из вершины первого сообщества в вершину второго.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Модулярность}

Однако подобными определениями сообществ пользоваться неудобно и их проверка достаточно долгая. В 2004 году была представлена \emph{модулярность} --- целевая функция, оценивающая неслучайность разбиения графа на сообщества \cite{Newman&Girvan:2004}. Допустим, у нас $K$ сообществ, определим тогда симметричную матрицу $\mathbf{e}$ размером $K \times K$. Пусть $e_{ij}$ --- отношение количества рёбер, которые идут из сообщества $i$ в сообщество $j$, к полному количеству рёбер в графе (рёбра $l_{mn}$ и $l_{nm}$ считаются различными, $m$, $n$ --- узлы). След такой матрицы $\mathrm{Tr} \mathbf{e} = \sum_{i \in 1..K}{e_{ii}}$ показывает отношение рёбер в сети, которые соединяют узлы одного и того же сообщества, и хорошее разбиение на сообщества должно иметь высокое значение следа. Однако если поместить все вершины в одно сообщество --- след примет максимальное возможное значение, притом, что такое разбиение не будет сообщать ничего полезного о графе.

Поэтому далее определяется вектор $\mathbf{a}$ длины K, элементы которой $a_i = \sum_{j \in 1..K}{e_{ij}}$, которая обозначает долю количества рёбер, идущих к узлам, принадлежащим сообществу $i$, к полному количеству рёбер в графе. Если в графе рёбра проходят между вершинами независимо от сообществ --- $e_{ij}$ будет в среднем равно $a_i a_j$, поэтому модулярность можно определить следующим образом:
\begin{equation} \label{eq:q1}
Q(G, P) = \sum_{i \in 1..K}{\left(e_{ii} - a_i^2\right)} = \mathrm{Tr} \mathbf{e} - \|\mathbf{e}^2\|,
\end{equation}
где $\|\mathbf{x}\|$ является суммой элементов матрицы $\mathbf{x}$. Если количество рёбер внутри сообществ не будет отличаться от случайного взятого количества --- модулярность будет примерно равна 0. Максимальным возможным значением функции будет 1, но на практике модулярности графов лежат между 0.3 и 0.7.

Было предложено несколько вариаций модулярности \cite{Muff&Rao&Caflisch:2005, Fortunato&Barthelemy:2007}. Так, эквивалентным приведённому выше определению будет
\begin{equation}
Q(G, P) = \frac{1}{2L} \sum_{x, y \in 1..N} \left(w_{xy} - \frac{s_x s_y}{2L}\right)\ \delta(c_P(x), c_P(y)),
\end{equation}
где $L$ --- мощность $\mathscr{L}$, $w_{xy}$ --- вес ребра между вершинами $x$ и $y$, $s_x$ и $s_y$ --- степени вершин $x$ и $y$ соответственно, $\delta$ --- символ Кронекера, а отображение $c_P(\cdot)$ указывает, в каком сообществе разбиения лежит узел графа.

Теперь можно поставить задачу выделения сообществ следующим образом: требуется найти такое разбиение графа, что модулярность примет максимальное значение. Можно заметить, что такая постановка не использует какого-либо определения сообществ, и получившиеся разбиение не проверяется на дополнительные свойства, кроме подсчёта модулярности. Однако такая задача всё ещё будет NP-сложной \cite{Brandes&al:2008}.

Преимущество модулярности состоит в том, что для того, чтобы посчитать, какой выигрыш мы извлечем из объединения двух сообществ, необходимо произвести только одну операцию. В рамках определения \eqref{eq:q1} такой выигрыш будет равен $\Delta Q = 2(e_{ij} - a_i a_j),$ где $i$ и $j$ --- потенциально объединяемые сообщества.

Для того, чтобы объединить два сообщества необходимо сделать $O(\min\{n_i, n_j\})$ операций, где $n_i$ и $n_j$ обозначают количество смежных к $i$ и $j$ сообществ. Не умоляя общности, $n_j \leq n_i$, тогда необходимо обновить столбец $i$-ый столбец и $i$-ую строку матрицы $\mathbf{e}$, а так же $i$-ый элемент вектора $\mathbf{a}$: $e_{ik} = e_{ki} = e_{ki} + e_{kj},$ где $k$ --- смежное к $j$ сообщество, и $a_{i} = a_{i} + a_{j}$. При этом сообщество $j$ следует удалить из дальнейшего рассмотрения.

Имея матрицу $\mathbf{e}$ и вектор $\mathbf{a}$ не очень важно, как устроен граф и сообщества, что позволяет искать сообщества, основываясь на некотором начальном разбиении, для которого построены $\mathbf{e}$ и $\mathbf{a}$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Рандомизированный жадный алгоритм}

Ньюман в 2004 году предложил алгоритм, максимизирующий модулярность \cite{Newman:2004}. Алгоритм начинается с разбиения графа на $N$ сообществ из одной вершины, а затем на каждой итерации просматривает все пары сообществ и соединяет ту пару, которая даст наибольший выигрыш модулярности. Такой алгоритм достаточно долго работает и страдает от несбалансированного объединения сообществ --- сообщества растут с разной скоростью, большие кластеры соединяются со своими небольшими соседями независимо от того, выгодно это глобально или нет \cite{Ovelgoenne&Geyer-Schulz:2012a}.

Поэтому был предложен рандомизированный жадный алгоритм (RG) \cite{Ovelgoenne&Geyer-Schulz:2010}, который на каждой итерации рассматривал $k$ случайных сообществ и смежных к ним сообществ, а затем так же соединял пару, дающую наибольший выигрыш. Трудоёмкость такого алгоритма примерно равна $O(kL \ln N)$. И первый алгоритм, и его рандомизированная вариация соединяют сообщества, записывая только номера соединений, до тех пор, пока не останется только одно сообщество, а затем создают разбиение из списка соединений до того момента, когда достигалась максимальная модулярность (так как в результате лучшего соединения модулярность может уменьшиться).

Можно отметить, что таким алгоритмом можно кластеризовать не только граф, но и граф с некоторым начальным разбиением, в котором можно сообщества разбивать дальше, но нельзя их соединять. При этом только немного поменяется начальный этап инициализации матрицы $\mathbf{e}$ и вектора $\mathbf{a}$ (смотри Алгоритм \ref{alg:RG}).

\begin{algorithm}[p]
\SetAlgoLined
\KwIn{Невзвешенный неориентированный граф $G = (\mathscr{N}, \mathscr{L})$, параметр $k$}
\KwOut{Разбиение на сообщества $P$}
\BlankLine
\For{$i \in 1..N$}{
	\For{$j \in 1..N$}{
		\eIf{$i$ и $j$ смежные}{
			$e[i, j] = 1 / (2 * L)$\;
		}{
			$e[i, j] = 0$\;
		}
	}
	$a[i] = \sum_j e[i, j]$\;
}
$global\Delta Q \leftarrow 0$\;
$max\_global\Delta Q \leftarrow -\infty$\;
\BlankLine
\For{$i \in 1..N$}{
	$max\Delta Q \leftarrow -\infty$\;
	\For{$j \in 1..k$}{
		$c1 \leftarrow$ случайное сообщество\;
		\ForAll{сообщества $c2$, смежные с $c1$}{
			$\Delta Q \leftarrow 2 * (e[i, j] - a[i] * a[j])$\;
			\If{$\Delta Q > max\Delta Q$}{
				$max\Delta Q \leftarrow \Delta Q$\;
				$next\_join \leftarrow (c1, c2)$\;
			}
		}
	}
	$joins\_list.push(next\_join)$\;
	$global\Delta Q \leftarrow global\Delta Q + max\Delta Q$\;
	\If{$global\Delta Q > max\_global\Delta Q$}{
		$max\_global\Delta Q \leftarrow global\Delta Q$\;
		$best\_step \leftarrow i$\;
	}
	\BlankLine
	$(c1, c2) \leftarrow next\_join$\;
	\If{количество соседей($c2$) > количество соседей($c1$)}{
		поменять местами $c1$ и $c2$\;
	}
	\ForAll{соседи $c3$ сообщества $c2$, где $c3 \neq c1, c2$}{
		$e[c3, c1] \leftarrow e[c3, c1] + e[c3, c2]$\;
		$e[c1, c3] \leftarrow e[c3, c1]$\;
	}
	$e[c1, c1] \leftarrow e[c1, c1] + e[c2, c2] + e[c1, c2] + e[c2, c1]$\;
	$a[c1] \leftarrow a[c1] + a[c2]$\;
}
\BlankLine
$P \leftarrow $ создать разбиение из $joins\_list[1..best\_step]$\;
\BlankLine
\caption{Рандомизированный жадный алгоритм}
\label{alg:RG}
\end{algorithm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Ансамблевая стратегия}
\label{subsec:ens}

Овельгённе и Гейер-Шульц в 2012 году выиграли 10th DIMACS Implementation Challenge с ансамблевой стратегией выделения сообществ (ES). Ансамблевая стратегия заключается в том, что сначала $s$ начальных алгоритмов разбивают граф на сообщества, и считается, что те вершины, в которых начальные алгоритмы сошлись во мнении определены по сообществам правильно, а те, которые остались, распределяет по сообществам финальный алгоритм \cite{Ovelgoenne&Geyer-Schulz:2012b}.

Формализовать это можно следующим образом:
\begin{enumerate}
	\item Создать множество $S$ из $s$ разбиений $G$ с помощью начальных алгоритмов
	\item Создать разбиение $\hat{P}$, равное максимальному перекрытию разбиений из множества $S$
	\item Финальным алгоритмом создать разбиение $\widetilde{P}$ графа $G$ на основе разбиения $\hat{P}$
\end{enumerate}

Необходимо определить понятие \emph{максимальное перекрытие}. Пусть у нас есть множество $S = \{P_1, \dots, P_s\}$, $c_P(v)$ указывает, в каком сообществе находится узел $v$ с разбиении $P$.
Тогда у максимального перекрытия $\hat{P}$ множества $S$ будут следующие свойства:
$$v, w \in \mathscr{N}, \forall i \in 1..s\ :\ c_{P_i}(v) = c_{P_i}(w) \Rightarrow c_{\hat{P}}(v) = c_{\hat{P}}(w)$$
$$v, w \in \mathscr{N}, \exists i \in 1..s\ :\ c_{P_i}(v) \ne c_{P_i}(w) \Rightarrow c_{\hat{P}}(v) \ne c_{\hat{P}}(w)$$

Ансамблевую стратегию можно итерировать, заставляя начальные алгоритмы разбивать максимальное перекрытие и получившееся максимальное перекрытие до тех пор, пока это будет увеличивать модулярность. В таком случае схема будет выглядеть следующим образом:

\begin{enumerate}
	\item Инициализировать $\hat{P}$ разбиением из сообществ из одного узла
	\item Создать множество $S$ из $s$ разбиений графа $G$ на основе разбиения $\hat{P}$ с помощью начальных алгоритмов
	\item Записать в $\hat{P}$ максимальное перекрытие множества $S$
	\item Если $P_{best}$ не существует или оно хуже, чем $\hat{P}$, то присвоить $P_{best} \leftarrow \hat{P}$ и вернуться на второй шаг
	\item Финальным алгоритмом создать разбиение $\widetilde{P}$ графа $G$ на основе разбиения $P_{best}$ 
\end{enumerate}

В качестве начальных и финального алгоритма можно брать рандомизированный жадный алгоритм.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Одновременно возмущаемая стохастическая аппроксимация}
Стохастические аппроксимация была введена Роббинсом и Монро в 1951 году \cite{Robbins&Monro:1951} и затем была использована для решения оптимизационный задач Кифером и Вольфовицем (KW) \cite{Kiefer&Wolfowitz:1952}. В \cite{Blum:1954} алгоритм стохастической аппроксимации был расширен до многомерного случая. В $m$-мерном пространстве обычная KW-процедура, основанная на конечно-разностной аппроксимации градиента, использовала $2m$ измерений на каждой итерации (по два измерения на каждую координату градиента). Спалл предложил алгоритм \emph{одновременно возмущаемой стохастической аппроксимации} (SPSA) \cite{Spall:1992}, который на каждой итерации использует всего два измерения. Он показал, что SPSA алгоритм имеет такую же скорость сходимости, несмотря на то, что в многомерном случае (даже при $m \to \infty$), несмотря на то, что в нём используется заметно меньше измерений \cite{Spall:2005}.

Стохастическая аппроксимация первоначально использовалась как инструмент для статистических вычислений и в дальнейшем разрбатывалась в рамках отдельной ветки теории управления. На сегодняшний день стохастическая аппроксимация имеет большое разнообразие применений в таких областях, как адаптивная обработка сигналов, адаптивное выделение ресурсов, адаптивное управление.

Алгоритмы стохастической аппроксимации показали свою эффективность в решении задач минимизации стационарных функционалов. В \cite{Polyak:1987} для функционалов, меняющихся со временем были применены метод Ньютона и градиентный метод, но они применимы только в случае дважды дифференцируемых функционалов и в случае известных ограничений на Гессиан функционала. Так же оба метода требуют возможности вычисления градиента в произвольной точке.

Общую схему одновременно возмущаемой стохастической аппроксимации можно представить следующим образом:

\begin{enumerate}
	\item Выбор начальной центральной точки $\theta_0 \in \mathbb{R}^m$, счётчик $n = 0$, выбор параметров алгоритма $d \in \mathbb{R} \setminus \{0\}$, $\{\alpha_n\} \subset \mathbb{R}^m$
	\item Увеличение счётчика $n \rightarrow n + 1$
	\item Выбор вектора возмущения $\Delta_n \in \mathbb{R}^m$, чьи координаты независимо генерируются и в среднем дают ноль. Часто для генерации компонент вектора используют распределение Бернулли, дающее $\pm1$ с вероятностью $\frac{1}{2}$ для каждого значения
	\item Определение новых аргументов функции $\theta_{n}^{-}=\hat{\theta}_{n - 1} - d\Delta_{n}$ и $\theta_{n}^{+}=\hat{\theta}_{n - 1} + d\Delta_{n}$
	\item Вычисление значений функционала $y_n^{-} = f(\theta_{n}^{-}), y_n^{+} = f(\theta_{n}^{+})$
	\item Вычисление следующей центральной точки
	\begin{equation} \label{eq:spsa-central}
		\hat{\theta}_n = \hat{\theta}_{n - 1} - \alpha_n \frac{y_n^{+} - y_n^{-}}{|\theta_{n}^{+} - \theta_{n}^{-}|}
	\end{equation}
	\item Далее происходит либо остановка алгоритма, либо переход на второй пункт
\end{enumerate}

В \cite{Granichin&Amelina:2015} был представлен метод стохастической аппроксимации с константным размером шага, в таком случае вместо последовательности $\{\alpha_n\}$ используется единственный параметр $\alpha \in \mathbb{R}^m$, и следующая центральная точка вычисляется по следующей формуле: $\hat{\theta}_n = \hat{\theta}_{n - 1} - \alpha \frac{y_n^{+} - y_n^{-}}{|\theta_{n}^{+} - \theta_{n}^{-}|}$


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Постановка задачи}

Рандомизированный жадный алгоритм имеет один параметр $k$, в то время как ансамблевая имеет стратегия один параметр $s$ и, в случае использования рандомизированного жадного алгоритма в качестве начального и финального алгоритма, будет иметь два дополнительных параметра $k_1$ и $k_2$, то есть в целом три параметра. Если на параметры рандомизированного жадного алгоритма поставить ограничения, к примеру, $k_1 = k_2$, то то можно считать, что ансамблевая стратегия имеет два параметра, $s$ и $k$.

Часто алгоритмы на каждых входных данных имеют разные оптимальные параметры, то есть параметры, решающие задачу наилучшим образом. И алгоритм SPSA показал хорошие результаты в адаптировании параметров подобных алгоритмов, в ходе работы рассматриваемого алгоритма его параметры варьируются, довольно быстро достигая оптимальной точки.

В данной работе будет рассматриваться применение алгоритма SPSA к двум алгоритмам выделения сообществ в графах, а так же сравнение модулярностей этих алгоритмов и их адаптивных модификаций.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Тестовые графы}

В качестве тестовых графов были взяты графы, используемые для оценки алгоритмов на 10th DIMACS Implementation Challenge. Далее представлены используемые графы с кратким описанием, в порядке увеличения веса файла в формате METIS Graph.

\begin{itemize}
	
	\item \textbf{karate}, $N = 34,\;L = 78$: социальная сеть между 34 членами карате клуба с 1970 по 1972 год \cite{Zachary:1977}
	\item \textbf{dolphins}, $N = 62,\;L = 159$: социальная сеть частых общений между 62 дельфинами \cite{Lusseau&al:2003}
	\item \textbf{chesapeake}, $N = 39,\;L = 170$: сеть мезогалинных вод Чесапикского залива \cite{Baird&Ulanowicz:1989}
	\item \textbf{adjnoun}, $N = 112,\;L = 425$: сеть смежности частых прилагательных и существительных в романе <<Давид Копперфильд>> Чарльза Диккенса \cite{Newman:2006}
	\item \textbf{polbooks}, $N = 105,\;L = 441$: сеть книг о политике США, изданных во время президентских выборов 2004 года. Рёбра между книгами означают частые покупки одними и теми же покупателями. Сеть скомпилирована Валдисом Кребсом, однако не была опубликована
	\item \textbf{football}, $N = 115,\;L = 613$: сеть игр в американский футбол между колледжами из дивизиона IA во время регулярного сезона осенью 2000 года \cite{Girvan&Newman:2002}
	\item \textbf{celegans\_metabolic}, $N = 453,\;L = 2025$: метаболическая сеть Caenorhabditis elegans \cite{Duch&Arenas:2005}
	\item \textbf{jazz}, $N = 198,\;L = 2742$: сеть джазовых музыкантов \cite{Gleiser&Danon:2003}
	\item \textbf{netscience}, $N = 1589,\;L = 2742$: сеть соавторства среди учёных, работающих над сложными сетями \cite{Newman:2006}
	\item \textbf{email}, $N = 1133,\;L = 5451$: сеть связей по электронной почте между членами Университета Ровира и Вирхилий \cite{Guimera&al:2003}
	\item \textbf{polblogs}, $N = 1490,\;L = 16715$: сеть ссылок между веб блогами о политике США в 2005 году \cite{Adamic&Glance:2005}
	\item \textbf{PGPgiantcompo}, $N = 10680,\;L = 24316$: список узлов гигантской компоненты сети пользователей алгоритма Pretty-Good-Privacy для защищенного обмена информацией \cite{Boguna&al:2004}
	\item \textbf{as-22july06}, $N = 22963,\;L = 48436$: структура интернета на уровне автономных систем на 22 июля 2006 года. Сеть создана Марком Ньюманом и не опубликована
	\item \textbf{cond-mat-2003}, $N = 31163,\;L = 120029$: сеть соавторства среди учёных, публиковавших препринты в определённые архивы между 1995 и 2003 годами \cite{Newman:2001}
	\item \textbf{caidaRouterLevel}, $N = 192244,\;L =  609066$: граф структуры интернета на уровне роутера, собранный ассоциацией CAIDA в апреле и мае 2003 года
	\item \textbf{cnr-2000}, $N = 325557,\;L = 2738969$: небольшая часть обхода итальянского домена .cnr \cite{Boldi&Vigna:2004, Boldi&al:2011, Boldi&al:2004}
	\item \textbf{in-2004}, $N = 1382908,\;L = 13591473$: небольшая часть обхода индийского домена .in \cite{Boldi&Vigna:2004, Boldi&al:2011, Boldi&al:2004}
	\item \textbf{eu-2005}, $N = 862664,\;L = 16138468$: небольшая часть обхода домена Европейского союза .eu \cite{Boldi&Vigna:2004, Boldi&al:2011, Boldi&al:2004}

\end{itemize}

Кроме того, некоторые тесты используют автоматически сгенерированные графы с заранее известным количеством сообществ. Такой граф имеет четыре параметра --- количество узлов $N$, количество сообществ $K$ (все сообщества одинаковых размеров), вероятность появления ребра между узлами одного сообщества $p_1$ и вероятность появления ребра между вершинами разных сообществ $p_2$. Преимущество автоматически сгенерированных графов заключается в проверке работы алгоритма на разных по размеру графах с разными по плотности сообществами. Так же из построения известны реальные сообщества. Однако графы, построенные по реальным системам могут сильно отличаться от подобных графов.

Так, далее в работе используется автоматически сгенерированный граф под названием \emph{auto40}, со следующими параметрами: $N = 40,000,\ K = 40,\ p_1 = 0.1,\ p_2 = 5\cdot 10^{-4}$.