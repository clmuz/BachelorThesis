\documentclass{matmex-diploma}

% \usepackage[no-math]{fontspec}		% XeLaTeX fonts
% \usepackage{polyglossia}        	% Babel for XeLaTeX
% \usepackage{hyperref}				% Ссылки внутри текста
% \usepackage{url}					% URL ссылки
% \usepackage{geometry}				% Margins
% \usepackage{mathspec}				% Math fonts
\usepackage{amssymb}				% For Real symbol
\usepackage{amsmath}				% Eqref
\usepackage{mathrsfs}				% Script Letters
\usepackage{pgfplots}       		% Графики
\usepackage{graphicx}       		% Работа с картинками
\usepackage{float}          		% Необходимо для указания места картинки на странице
\usepackage{algorithm2e}			% Algorithm

% ------------------- Русский для algorithm2e
\SetKwInput{KwData}{Исходные параметры}
\SetKwInput{KwResult}{Результат}
\SetKwInput{KwIn}{Входные данные}
\SetKwInput{KwOut}{Выходные данные}
\SetAlgorithmName{Алгоритм}{алгоритм}{Список алгоритмов}
\SetArgSty{textnormal}
\SetKwFor{ForAll}{forall}{do}{end}
% ------------------- Русский для algorithm2e

\begin{document}
\filltitle{ru}{
    chair              = {Кафедра Информатики},
    title              = {Адаптивный рандомизированный алгоритм выделения сообществ в графах},
    % Здесь указывается тип работы. Возможные значения:
    %   coursework - Курсовая работа
    %   diploma - Диплом специалиста
    %   master - Диплом магистра
    %   bachelor - Диплом бакалавра
    type               = {bachelor},
    position           = {студента},
    group              = 442,
    author             = {Проданов Тимофей Петрович},
    supervisorPosition = {д. ф.-м. н., профессор},
    supervisor         = {О.Н. Граничин},
    reviewerPosition   = {},
    reviewer           = {В.А. Ерофеева},
    chairHeadPosition  = {},
    chairHead          = {},
%   university         = {Санкт-Петербургский Государственный Университет},
%   faculty            = {Математико-механический факультет},
%   city               = {Санкт-Петербург},
%   year               = {2013}
}
\filltitle{en}{
    chair              = {Department of Computer Science},
    title              = {Adaptive randomised algorithm for community detection in graphs},
    type 			   = {bachelor},
    author             = {Timofey Prodanov},
    supervisorPosition = {Professor},
    supervisor         = {Oleg Granichin},
    reviewerPosition   = {},
    reviewer           = {Victoria Erofeeva},
    chairHeadPosition  = {},
    chairHead          = {},
}

\maketitle
\tableofcontents

\section*{Введение}

\section{Предварительные сведения}

\subsection{Выделение сообществ в графах}
Исторически, изучение сетей происходило в рамках теории графов, которая начала своё существование с решения Леонардом Эйлером задачи о кёнигсбергских мостах. В 1920-х взял своё начало анализ социальных сетей и лишь последние двадцать лет развивается изучение \emph{сложных сетей}, то есть сетей с неправильной, сложной структурой, в некоторых случаях рассматривают динамически меняющейся во времени сложные сети. От изучения маленьких сетей внимание переходит к сетям из тысяч или миллионов узлов.

В процессе изучения сложных систем, построенных по реальным системам, оказалось, что распределение степеней $P(s)$, определённое как доля узлов со степенью $s$ среди всех узлов графа, сильно отличается от распределения Пуассона, которое ожидается для случайных графов. Также сети, построенные по реальным системам характеризуются короткими путями между любыми двумя узлами и большим количеством маленьких циклов\cite{Boccaletti&al:2006}. Это показывает, что модели, предложенные теорией графов, часто будут оказываться далеко от реальных потребностей.

Современное изучение сложных сетей привнесло значительный вклад в понимание реальных систем. Сложные сети с успехом были применены в таких разных областях, как изучение структуры и топологии интернета \cite{Faloutsos&al:1999, Broder&al:2000}, эпидемиологии \cite{Moore&Newman:2000}, биоинформатике \cite{Zhao&al:2006}, поиске преступников \cite{Hong&al:2009}, социологии \cite{Scott:2012} и многих других.

Свойством, присутствуещим почти у любой сети, является структура сообществ, разделение узлов сети на разные группы узлов так, чтобы внутри каждой группы соединений между узлами много, а соединений между узлами разных групп мало. Способность находить и анализировать подобные группы предоставляет большие возможности в изучении реальных систем, представленных с помощью сложных сетей. Плотно связанные группы узлов в социальных сетях представляют людей, принадлежащих социальным сообществам, плотно сплочённые группы узлов в интернете соответствуют страницам, посвящённым распространённым темам, а сообщества в генетических сетях связаны с функциональными модулями \cite{Boccaletti&al:2006}. Таким образом, выделение сообществ в сети является мощным инструментом для понимания функциональности сети.

\subsection{Определения и обозначения}

Формально, сложная система может быть представлена с помощью графа. В этой работе будут рассматриваться только невзвешенные неориентированные графы. Неориентированный невзвешенный граф $G = (\mathscr{N}, \mathscr{L})$ состоит из двух множеств --- множества $\mathscr{N} \ne \emptyset$, элементы которого называются \emph{узлами} или \emph{вершинами} графа, и множества $\mathscr{L}$ неупорядоченных пар из множества $\mathscr{N}$, элементы которого называются \emph{рёбрами} или \emph{связями}. Мощности множеств $\mathscr{N}$ и $\mathscr{L}$ равны $N$ и $L$ соответственно.

Подграфом называется граф $G' = (\mathscr{N}', \mathscr{L}')$, где $\mathscr{N}' \subset \mathscr{N}$ и $\mathscr{L}' \subset \mathscr{L}$.

Узел обычно обозначают по его порядковому месту $i$ в множестве $\mathscr{N}$, а ребро, соединяющее пару узлов $i$ и $j$ обозначается $l_{ij}$. Узлы, между которыми есть ребро называются \emph{смежными}. Степенью узла назовём величину $s_i$, равную количеству рёбер, выходящих узла $i$.

Прогулка из узла $i$ в узел $j$ --- это последовательность узлов, начинающаяся с узла $i$ и заканчивающаяся узлом $j$. Путь --- это прогулка, в которой каждый узел встречается единожды. Геодезический путь --- это кратчайший путь, а количество узлов в нём на один больше геодезического расстояния.

До того, как мы определили понятие \emph{сообщество}, определим \emph{разбиение} на сообщества. Пусть $G = (\mathscr{N}, \mathscr{L})$ --- граф, тогда разбиением на сообщества будет называться разбиение множества его вершин $P = \{C_1, \dots, C_K\}$, то есть $\bigcup_{i = 1}^K C_i = \mathscr{N}$ и $C_i \cap C_j = \emptyset \ \forall i \neq j \in 1..K$.

Сообщество --- это такой подграф, чьи узлы плотно связаны, однако структурная сплочённость узлов можно определить по разному. Одно из определений вводит понятие \emph{клик}. Клик --- это максимальный такой подграф, состоящий из трёх и более вершин, каждая из которых связана с каждой другой вершиной из клика. $n$-клик --- это максимальный подграф, в котором самое большое геодезическое расстояние между любыми двумя вершинами не превосходит $n$. Другое определение гласит, что подграф $G'$ является сообществом, если сумма всех степеней внутри $G'$ больше суммы всех степеней, направленных в остальную часть графа \cite{Wasserman:1994}. Сообщества называются смежными, если существует ребро, направленное из вершины первого сообщества в вершину второго.

\subsection{Модулярность}
Однако подобными определениями сообществ пользоваться неудобно и их проверка достаточно долгая. В 2004 году была представлена \emph{модулярность} --- целевая функция, оценивающая неслучайность разбиения графа на сообщества \cite{Newman&Girvan:2004}. Допустим, у нас $K$ сообществ, определим тогда симметричную матрицу $\mathbf{e}$ размером $K \times K$. Пусть $e_{ij}$ --- отношение количества рёбер, которые идут из сообщества $i$ в сообщество $j$, к полному количеству рёбер в графе (рёбра $l_{mn}$ и $l_{nm}$ считаются различными, $m$, $n$ --- узлы). След такой матрицы $\mathrm{Tr} \mathbf{e} = \sum_{i \in 1..K}{e_{ii}}$ показывает отношение рёбер в сети, которые соединяют узлы одного и того же сообщества, и хорошее разбиение на сообщества должно иметь высокое значение следа. Однако если поместить все вершины в одно сообщество --- след примет максимальное возможное значение, притом, что такое разбиение не будет сообщать ничего полезного о графе.

Поэтому далее определяется вектор $\mathbf{a}$ длины K, элементы которой $a_i = \sum_{j \in 1..K}{e_{ij}}$, которая обозначает долю количества рёбер, идущих к узлам, принадлежащим сообществу $i$, к полному количеству рёбер в графе. Если в графе рёбра проходят между вершинами независимо от сообществ --- $e_{ij}$ будет в среднем равно $a_i a_j$, поэтому модулярность можно определить следующим образом:
\begin{equation} \label{eq:q1}
Q(G, P) = \sum_{i \in 1..K}{\left(e_{ii} - a_i^2\right)} = \mathrm{Tr} \mathbf{e} - \|\mathbf{e}^2\|,
\end{equation}
где $\|\mathbf{x}\|$ является суммой элементов матрицы $\mathbf{x}$. Если количество рёбер внутри сообществ не будет отличаться от случайного взятого количества --- модулярность будет примерно равна 0. Максимальным возможным значением функции будет 1, но на практике модулярности графов лежат между 0.3 и 0.7.

Было предложено несколько вариаций модулярности \cite{Muff&Rao&Caflisch:2005, Fortunato&Barthelemy:2007}. Так, эквивалентным приведённому выше определению будет
\begin{equation}
Q(G, P) = \frac{1}{2L} \sum_{x, y \in 1..N} \left(w_{xy} - \frac{s_x s_y}{2L}\right)\ \delta(c_P(x), c_P(y)),
\end{equation}
где $L$ --- мощность $\mathscr{L}$, $w_{xy}$ --- вес ребра между вершинами $x$ и $y$, $s_x$ и $s_y$ --- степени вершин $x$ и $y$ соответственно, $\delta$ --- символ Кронекера, а отображение $c_P(\cdot)$ указывает, в каком сообществе разбиения лежит узел графа.

Теперь можно поставить задачу выделения сообществ следующим образом: требуется найти такое разбиение графа, что модулярность примет максимальное значение. Можно заметить, что такая постановка не использует какого-либо определения сообществ, и получившиеся разбиение не проверяется на дополнительные свойства, кроме подсчёта модулярности. Однако такая задача всё ещё будет NP-сложной \cite{Brandes&al:2008}.

Преимущество модулярности состоит в том, что для того, чтобы посчитать, какой выигрыш мы извлечем из объединения двух сообществ, необходимо произвести только одну операцию. В рамках определения \eqref{eq:q1} такой выигрыш будет равен $\Delta Q = 2(e_{ij} - a_i a_j),$ где $i$ и $j$ --- потенциально объединяемые сообщества.

Для того, чтобы объединить два сообщества необходимо сделать $O(\min\{n_i, n_j\})$ операций, где $n_i$ и $n_j$ обозначают количество смежных к $i$ и $j$ сообществ. Не умоляя общности, $n_j \leq n_i$, тогда необходимо обновить столбец $i$-ый столбец и $i$-ую строку матрицы $\mathbf{e}$, а так же $i$-ый элемент вектора $\mathbf{a}$: $e_{ik} = e_{ki} = e_{ki} + e_{kj},$ где $k$ --- смежное к $j$ сообщество, и $a_{i} = a_{i} + a_{j}$. При этом сообщество $j$ следует удалить из дальнейшего рассмотрения.

Имея матрицу $\mathbf{e}$ и вектор $\mathbf{a}$ не очень важно, как устроен граф и сообщества, что позволяет искать сообщества, основываясь на некотором начальном разбиении, для которого построены $\mathbf{e}$ и $\mathbf{a}$.

\subsection{Рандомизированный жадный алгоритм}
Ньюман в 2004 году предложил алгоритм, максимизирующий модулярность \cite{Newman:2004}. Алгоритм начинается с разбиения графа на $N$ сообществ из одной вершины, а затем на каждой итерации просматривает все пары сообществ и соединяет ту пару, которая даст наибольший выигрыш модулярности. Такой алгоритм достаточно долго работает и страдает от несбалансированного объединения сообществ --- сообщества растут с разной скоростью, большие кластеры соединяются со своими небольшими соседями независимо от того, выгодно это глобально или нет \cite{Ovelgoenne&Geyer-Schulz:2012a}.

Поэтому был предложен рандомизированный жадный алгоритм (RG) \cite{Ovelgoenne&Geyer-Schulz:2010}, который на каждой итерации рассматривал $k$ случайных сообществ и смежных к ним сообществ, а затем так же соединял пару, дающую наибольший выигрыш. Трудоёмкость такого алгоритма примерно равна $O(L \ln N)$. И первый алгоритм, и его рандомизированная вариация соединяют сообщества, записывая только номера соединений, до тех пор, пока не останется только одно сообщество, а затем создают разбиение из списка соединений до того момента, когда достигалась максимальная модулярность (так как в результате лучшего соединения модулярность может уменьшиться).

Можно отметить, что таким алгоритмом можно кластеризовать не только граф, но и граф с некоторым начальным разбиением, в котором можно сообщества разбивать дальше, но нельзя их соединять. При этом только немного поменяется начальный этап инициализации матрицы $\mathbf{e}$ и вектора $\mathbf{a}$ (смотри Алгоритм \ref{alg:RG}).

\begin{algorithm}[p]
\SetAlgoLined
\KwIn{Невзвешенный неориентированный граф $G = (\mathscr{N}, \mathscr{L})$, параметр $k$}
\KwOut{Разбиение на сообщества $P$}
\BlankLine
\For{$i \in 1..N$}{
	\For{$j \in 1..N$}{
		\eIf{$i$ и $j$ смежные}{
			$e[i, j] = 1 / (2 * L)$\;
		}{
			$e[i, j] = 0$\;
		}
	}
	$a[i] = \sum_j e[i, j]$\;
}
$global\Delta Q \leftarrow 0$\;
$max\_global\Delta Q \leftarrow -\infty$\;
\BlankLine
\For{$i \in 1..N$}{
	$max\Delta Q \leftarrow -\infty$\;
	\For{$j \in 1..k$}{
		$c1 \leftarrow$ случайное сообщество\;
		\ForAll{сообщества $c2$, смежные с $c1$}{
			$\Delta Q \leftarrow 2 * (e[i, j] - a[i] * a[j])$\;
			\If{$\Delta Q > max\Delta Q$}{
				$max\Delta Q \leftarrow \Delta Q$\;
				$next\_join \leftarrow (c1, c2)$\;
			}
		}
	}
	$joins\_list.push(next\_join)$\;
	$global\Delta Q \leftarrow global\Delta Q + max\Delta Q$\;
	\If{$global\Delta Q > max\_global\Delta Q$}{
		$max\_global\Delta Q \leftarrow global\Delta Q$\;
		$best\_step \leftarrow i$\;
	}
	\BlankLine
	$(c1, c2) \leftarrow next\_join$\;
	\If{количество соседей($c2$) > количество соседей($c1$)}{
		поменять местами $c1$ и $c2$\;
	}
	\ForAll{соседи $c3$ сообщества $c2$, где $c3 \neq c1, c2$}{
		$e[c3, c1] \leftarrow e[c3, c1] + e[c3, c2]$\;
		$e[c1, c3] \leftarrow e[c3, c1]$\;
	}
	$e[c1, c1] \leftarrow e[c1, c1] + e[c2, c2] + e[c1, c2] + e[c2, c1]$\;
	$a[c1] \leftarrow a[c1] + a[c2]$\;
}
\BlankLine
$P \leftarrow $ создать разбиение из $joins\_list[1..best\_step]$\;
\BlankLine
\caption{Рандомизированный жадный алгоритм}
\label{alg:RG}
\end{algorithm}

\subsection{Ансамблевая стратегия}
Овельгённе и Гейер-Шульц в 2012 году выиграли 10th DIMACS Implementation Challenge с ансамблевой стратегией выделения сообществ (ES). Ансамблевая стратегия заключается в том, что сначала $s$ начальных алгоритмов разбивают граф на сообщества, и считается, что те вершины, в которых начальные алгоритмы сошлись во мнении определены по сообществам правильно, а те, которые остались, распределяет по сообществам финальный алгоритм \cite{Ovelgoenne&Geyer-Schulz:2012b}.

Формализовать это можно следующим образом:
\begin{enumerate}
	\item Создать множество $S$ из $s$ разбиений $G$ с помощью начальных алгоритмов
	\item Создать разбиение $\hat{P}$, равное максимальному перекрытию разбиений из множества $S$
	\item Финальным алгоритмом создать разбиение $\widetilde{P}$ графа $G$ на основе разбиения $\hat{P}$
\end{enumerate}

Необходимо определить понятие \emph{максимальное перекрытие}. Пусть у нас есть множество $S = \{P_1, \dots, P_s\}$, $c_P(v)$ указывает, в каком сообществе находится узел $v$ с разбиении $P$.
Тогда у максимального перекрытия $\hat{P}$ множества $S$ будут следующие свойства:
$$v, w \in \mathscr{N}, \forall i \in 1..s\ :\ c_{P_i}(v) = c_{P_i}(w) \Rightarrow c_{\hat{P}}(v) = c_{\hat{P}}(w)$$
$$v, w \in \mathscr{N}, \exists i \in 1..s\ :\ c_{P_i}(v) \ne c_{P_i}(w) \Rightarrow c_{\hat{P}}(v) \ne c_{\hat{P}}(w)$$

Ансамблевую стратегию можно итерировать, заставляя начальные алгоритмы разбивать максимальное перекрытие и получившееся максимальное перекрытие до тех пор, пока это будет увеличивать модулярность. В таком случае схема будет выглядеть следующим образом:

\begin{enumerate}
	\item Инициализировать $\hat{P}$ разбиением из сообществ из одного узла
	\item Создать множество $S$ из $s$ разбиений графа $G$ на основе разбиения $\hat{P}$ с помощью начальных алгоритмов
	\item Записать в $\hat{P}$ максимальное перекрытие множества $S$
	\item Если $P_{best}$ не существует или оно хуже, чем $\hat{P}$, то присвоить $P_{best} \leftarrow \hat{P}$ и вернуться на второй шаг
	\item Финальным алгоритмом создать разбиение $\widetilde{P}$ графа $G$ на основе разбиения $P_{best}$ 
\end{enumerate}

\subsection{Одновременно возмущаемая стохастическая аппроксимация}
Стохастические аппроксимация была введена Роббинсом и Монро в 1951 году \cite{Robbins&Monro:1951} и затем была использована для решения оптимизационный задач Кифером и Вольфовицем (KW) \cite{Kiefer&Wolfowitz:1952}. В \cite{Blum:1954} алгоритм стохастической аппроксимации был расширен до многомерного случая. В $m$-мерном пространстве обычная KW-процедура, основанная на конечно-разностной аппроксимации градиента, использовала $2m$ измерений на каждой итерации (по два измерения на каждую координату градиента). Спалл предложил алгоритм \emph{одновременно возмущаемой стохастической аппроксимации} (SPSA) \cite{Spall:1992}, который на каждой итерации использует всего два измерения. Он показал, что SPSA алгоритм имеет такую же скорость сходимости, несмотря на то, что в многомерном случае (даже при $m \to \infty$), несмотря на то, что в нём используется заметно меньше измерений \cite{Spall:2005}.

Стохастическая аппроксимация первоначально использовалась как инструмент для статистических вычислений и в дальнейшем разрбатывалась в рамках отдельной ветки теории управления. На сегодняшний день стохастическая аппроксимация имеет большое разнообразие применений в таких областях, как адаптивная обработка сигналов, адаптивное выделение ресурсов, адаптивное управление.

Алгоритмы стохастической аппроксимации показали свою эффективность в решении задач минимизации стационарных функционалов. В \cite{Polyak:1987} для функционалов, меняющихся со временем были применены метод Ньютона и градиентный метод, но они применимы только в случае дважды дифференцируемых функционалов и в случае известных ограничений на Гессиан функционала. Так же оба метода требуют возможности вычисления градиента в произвольной точке.

Общую схему одновременно возмущаемой стохастической аппроксимации можно представить следующим образом:

\begin{enumerate}
	\item Выбор начальной центральной точки $\theta_0 \in \mathbb{R}^m$, счётчик $n = 0$, выбор параметров алгоритма $d \in \mathbb{R} \setminus \{0\}$, $\{\alpha_n\} \subset \mathbb{R}^m$
	\item Увеличение счётчика $n \rightarrow n + 1$
	\item Выбор вектора возмущения $\Delta_n \in \mathbb{R}^m$, чьи координаты независимо генерируются и в среднем дают ноль. Часто для генерации компонент вектора используют распределение Бернулли, дающее $\pm1$ с вероятностью $\frac{1}{2}$ для каждого значения
	\item Определение новых аргументов функции $\theta_{n}^{-}=\hat{\theta}_{n - 1} - d\Delta_{n}$ и $\theta_{n}^{+}=\hat{\theta}_{n - 1} + d\Delta_{n}$
	\item Вычисление значений функционала $y_n^{-} = f(\theta_{n}^{-}), y_n^{+} = f(\theta_{n}^{+})$
	\item Вычисление следующей центральной точки 
	$$\hat{\theta}_n = \hat{\theta}_{n - 1} - \alpha_n \frac{y_n^{+} - y_n^{-}}{|\theta_{n}^{+} - \theta_{n}^{-}|}$$
	\item Далее происходит либо остановка алгоритма, либо переход на второй пункт
\end{enumerate}

В \cite{Granichin&Amelina:2015} был представлен метод стохастической аппроксимации с константным размером шага, в таком случае вместо последовательности $\{\alpha_n\}$ используется единственный параметр $\alpha \in \mathbb{R}^m$, и следующая центральная точка вычисляется по следующей формуле: $\hat{\theta}_n = \hat{\theta}_{n - 1} - \alpha \frac{y_n^{+} - y_n^{-}}{|\theta_{n}^{+} - \theta_{n}^{-}|}$

\bibliographystyle{unsrt}
\bibliography{diploma}

\end{document}